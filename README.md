# Aaron W. Storey

**PhD Candidate | Explainable AI Researcher | Opening the Black Box**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/astoreyai/)
[![ORCID](https://img.shields.io/badge/ORCID-A6CE39?style=flat&logo=orcid&logoColor=white)](https://orcid.org/0009-0009-5560-0015)
[![IEEE](https://img.shields.io/badge/IEEE-Member-00629B?style=flat&logo=ieee&logoColor=white)](https://ieee.org)

---

## Research Focus

Making AI interpretable, trustworthy, and auditable.

| Area | Focus |
|------|-------|
| **XAI Methods** | Attribution, counterfactuals, faithful explanations |
| **Transformer Interpretability** | Logic-gated modules, attention probes, mechanistic analysis |
| **Adversarial ML** | Robustness testing, perturbation analysis, model brittleness |
| **Applications** | Biometrics, LLMs, vision models, safety-critical systems |

**PhD Thesis**: Developing falsifiable attribution methods for explainable AI - systems that can be empirically validated and audited.

**Proposal**: January 2026 | **Defense**: November 2026 @ Clarkson University

---

## Featured Projects

| Project | Description | Status |
|---------|-------------|--------|
| [SIFTER](https://github.com/Bespoke-Robot-Society/SIFTER) | NASA Space Apps 2024: ML seismic detection for moon/marsquakes | NASA Hackathon |
| [100 Days of ML](https://100daysofml.github.io/) | Complete 35-lesson curriculum: Python basics to XGBoost | ![Stars](https://img.shields.io/github/stars/100daysofml/100daysofml.github.io?style=flat) |
| [Money Talks](https://github.com/astoreyai/money-talks) | Trading & investing education: 100 notebooks, 5 classes | 37/100 complete |
| [Research Assistant](https://github.com/astoreyai/ai_scientist) | PRISMA 2020 + NIH-compliant research workflow automation | 22 skills, 10 agents |
| [Claude Skills](https://github.com/astoreyai/claude-skills) | Automation skills for Claude Code | 32+ skills |

---

## Current Work

- **AI Engineer @ Kymera Systems**: Building intelligent AI orchestration systems
- **IEEE T-BIOM Submission**: Beta regression framework for bounded biometric performance metrics
- **Dissertation**: Faithful explanations that withstand adversarial probing
- **Tools**: Building research automation for reproducible science

---

## Tech Stack

![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![LaTeX](https://img.shields.io/badge/LaTeX-008080?style=flat&logo=latex&logoColor=white)

---

## GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=astoreyai&show_icons=true&theme=default&hide_border=true" alt="GitHub Stats" />
</p>

<p align="center">
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=astoreyai&theme=default&hide_border=true" alt="GitHub Streak" />
</p>

---

## Connect

- **Portfolio**: [astoreyai.github.io](https://astoreyai.github.io)
- **LinkedIn**: [linkedin.com/in/astoreyai](https://www.linkedin.com/in/astoreyai/)
- **ORCID**: [0009-0009-5560-0015](https://orcid.org/0009-0009-5560-0015)
- **Email**: storeyaw@clarkson.edu

---

*"Make explainability an engineering discipline: measurable faithfulness, human factors by design, and governance that withstands audits."*
