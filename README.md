# Aaron W. Storey

**PhD Candidate | Explainable AI Researcher | Opening the Black Box**

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/astoreyai/)
[![ORCID](https://img.shields.io/badge/ORCID-A6CE39?style=flat&logo=orcid&logoColor=white)](https://orcid.org/0009-0009-5560-0015)
[![IEEE](https://img.shields.io/badge/IEEE-Member-00629B?style=flat&logo=ieee&logoColor=white)](https://ieee.org)

---

## Research Focus

Making AI interpretable, trustworthy, and auditable.

| Area | Focus |
|------|-------|
| **XAI Methods** | Attribution, counterfactuals, faithful explanations |
| **Transformer Interpretability** | Logic-gated modules, attention probes, mechanistic analysis |
| **Adversarial ML** | Robustness testing, perturbation analysis, model brittleness |
| **Applications** | Biometrics, LLMs, vision models, safety-critical systems |

**PhD Thesis**: Developing falsifiable attribution methods for explainable AI - systems that can be empirically validated and audited.

**Proposal Defense**: February 2026 @ Clarkson University

---

## Featured Projects

| Project | Description | Status |
|---------|-------------|--------|
| [Beta Regression Framework](https://github.com/astoreyai/beta-regression-pediatricface) | Statistical framework for bounded biometric performance in child face recognition | IEEE T-BIOM |
| [Agentic AI Seminar](https://github.com/astoreyai/agentic) | Personas & affective prompting as behavioral control surfaces | Clarkson Seminar |
| [Goblin Forge](https://github.com/astoreyai/goblin-forge) | Multi-agent CLI orchestrator for Linux with tmux isolation | Active Dev |
| [SIFTER](https://github.com/Bespoke-Robot-Society/SIFTER) | NASA Space Apps 2024: ML seismic detection for moon/marsquakes | NASA Hackathon |
| [100 Days of ML](https://100daysofml.github.io/) | Complete 35-lesson curriculum: Python basics to XGBoost | ![Stars](https://img.shields.io/github/stars/100daysofml/100daysofml.github.io?style=flat) |
| [Research Assistant](https://github.com/astoreyai/ai_scientist) | PRISMA 2020 + NIH-compliant research workflow automation | 22 skills, 10 agents |
| [EE622: Biometrics Transformers](https://github.com/clarkson-edge/ee622) | 10-week graduate course: ViT for fingerprint, face, gait, speaker, ECG | Clarkson University |

---

## Current Work

- **Dissertation**: Counterfactual frameworks for falsifiable attribution in face verification
- **IEEE T-BIOM** (Under Review): Beta regression for bounded biometric metrics
- **IEEE T-BIOM** (In Preparation): AI Act/GDPR/Daubert â†’ XAI validation framework
- **MDPI Electronics** (Under Review): Hardware security review for embedded processors
- **In Preparation**: Affective prompting & persona manipulation systematic review
- **AI Engineer @ Kymera Systems**: Building intelligent AI orchestration systems

---

## Tech Stack

![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![Go](https://img.shields.io/badge/Go-00ADD8?style=flat&logo=go&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=flat&logo=scikit-learn&logoColor=white)
![LaTeX](https://img.shields.io/badge/LaTeX-008080?style=flat&logo=latex&logoColor=white)

---

## GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=astoreyai&show_icons=true&theme=nord&hide_border=true&include_all_commits=true&count_private=true" alt="GitHub Stats" />
</p>

<p align="center">
  <img src="https://streak-stats.demolab.com/?user=astoreyai&theme=nord&hide_border=true" alt="GitHub Streak" />
</p>

---

## Connect

- **Portfolio**: [astoreyai.github.io](https://astoreyai.github.io)
- **LinkedIn**: [linkedin.com/in/astoreyai](https://www.linkedin.com/in/astoreyai/)
- **ORCID**: [0009-0009-5560-0015](https://orcid.org/0009-0009-5560-0015)
- **Email**: storeyaw@clarkson.edu

---

*"Make explainability an engineering discipline: measurable faithfulness, human factors by design, and governance that withstands audits."*
