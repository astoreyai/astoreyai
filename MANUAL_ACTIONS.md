# Personal Branding Manual Actions Guide

**Last Updated**: December 2025

---

## GITHUB ACTIONS

### 1. Update GitHub Bio
Go to: https://github.com/settings/profile

**Bio** (160 chars max):
```
PhD Candidate | Explainable AI | Opening the Black Box | AI Engineer @ Kymera Systems
```

**Company**: Kymera Systems
**Location**: (your preference)
**Website**: https://astoreyai.github.io

### 2. Pin Repositories
Go to: https://github.com/astoreyai (click "Customize your pins")

**Pin these 6 repos** (in order):
1. `astoreyai/astoreyai` - Profile README
2. `astoreyai/money-talks` - Trading education
3. `astoreyai/ai_scientist` - Research assistant
4. `astoreyai/claude-skills` - Claude automation
5. `astoreyai/biometric_fingerprint_mcp` - MCP server
6. `100daysofml/100daysofml.github.io` - ML curriculum (if you're a member, otherwise pin another)

---

## LINKEDIN ACTIONS

### 1. Featured Section (ADD THESE)

LinkedIn Featured section shows media/links prominently on your profile. Add these 3 items:

### Item 1: GitHub Profile
- **Type**: Link
- **URL**: https://github.com/astoreyai
- **Title**: GitHub Profile - Explainable AI Research & Tools
- **Description**: PhD research, educational content, and open-source tools for XAI, transformers, and ML automation.

### Item 2: 100 Days of ML
- **Type**: Link
- **URL**: https://100daysofml.github.io
- **Title**: 100 Days of Machine Learning
- **Description**: Complete 35-lesson curriculum from Python basics to XGBoost. Open-source educational resource with Google Colab integration.

### Item 3: Research Summary (optional - create as a post first)
- **Type**: Post or Document
- **Title**: My PhD Research: Opening the Black Box
- **Content**: Brief overview of your XAI research - transformer interpretability, faithful explanations, adversarial robustness

---

## 2. About Section Addition

Add this block at the END of your current About section:

```
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

CONNECT & EXPLORE
‚Ä¢ GitHub: github.com/astoreyai
‚Ä¢ Portfolio: astoreyai.github.io
‚Ä¢ 100 Days of ML: 100daysofml.github.io
‚Ä¢ ORCID: 0009-0009-5560-0015
```

---

## 3. Graduate Research Assistant Description Update

Replace/enhance your current description with:

**Current Role** (Jun 2025 - Present)

PhD Candidate researching Explainable AI (XAI) methods for trustworthy, auditable AI systems.

Research Focus:
‚Ä¢ Transformer interpretability: logic-gated modules, attention probes, mechanistic analysis
‚Ä¢ Faithful explanations: attribution methods, counterfactual probes, stability testing
‚Ä¢ Adversarial robustness: perturbation analysis, model brittleness, edge cases
‚Ä¢ Applications: Biometrics, LLMs, vision models, safety-critical systems

Dissertation: Developing falsifiable attribution methods that can be empirically validated and audited.

Proposal: January 2026 | Defense: November 2026

Publication: IEEE T-BIOM submission - Beta regression framework for bounded biometric metrics

---

## 4. Weekly Content Ideas (First 4 Posts)

### Post 1: Research Introduction
```
Opening the Black Box: My PhD Journey

I'm 6 months into my PhD at Clarkson University, focused on one question:

How do we know if an AI explanation is actually faithful to what the model is doing?

Most XAI methods give us *something* - saliency maps, attention weights, feature importance. But are these explanations reliable? Can we trust them?

My research develops methods to empirically test explanation faithfulness through:
- Adversarial probing
- Counterfactual analysis
- Stability testing across perturbations

The goal: Make explainability an engineering discipline with measurable standards.

Proposal: January 2026 | Defense: November 2026

#ExplainableAI #XAI #PhDLife #MachineLearning #TrustworthyAI
```

### Post 2: Educational Content
```
If you're learning ML in 2025, here's the path that actually works:

1. Python fundamentals (not just syntax - data structures, flow control)
2. Math foundations (linear algebra + calculus + probability)
3. Data preprocessing (80% of real ML work)
4. Classical algorithms first (regression, trees, SVM)
5. THEN deep learning

I co-created a free curriculum that follows this exact path:
100 Days of Machine Learning - 35 lessons from basics to ensemble methods

No paywalls. No fluff. Just structured learning with Colab notebooks.

Link in comments üëá

#MachineLearning #DataScience #Learning #Education
```

### Post 3: Technical Insight
```
Attention weights ‚â† explanation.

One of the biggest misconceptions in XAI:

"The model attended to these tokens, so that's why it made this prediction."

Problems:
1. Attention is often distributed, not focused
2. Attention patterns don't always correlate with model behavior
3. You can get identical outputs with different attention patterns

What works better:
- Gradient-based attribution (with sanity checks)
- Counterfactual probes (what changes the output?)
- Mechanistic interpretability (circuit analysis)

The key insight: Always test if your explanation is *faithful* to what the model actually does.

#ExplainableAI #NLP #Transformers #MachineLearning
```

### Post 4: Milestone/Progress
```
PhD Progress Update: Month 6

‚úì Completed: Literature review on faithful explanations
‚úì Completed: Beta regression framework (IEEE T-BIOM submission)
‚úì In progress: Experimental validation framework

Next: Adversarial probing experiments on transformer attention

6 months in. Proposal: January 2026. Defense: November 2026.

The hardest part so far? Narrowing scope. XAI is vast - staying focused on falsifiable methods.

What's helped: Weekly writing habit. Even 500 words of rough notes compounds over time.

Any other PhD candidates in the XAI/trustworthy AI space? Would love to connect.

#PhDLife #AcademicTwitter #ExplainableAI #Research
```

---

## 5. Quick Action Checklist

**GitHub (do first)**:
- [ ] Update bio at github.com/settings/profile
- [ ] Pin 6 repos at github.com/astoreyai

**LinkedIn**:
- [ ] Add Featured section with 2-3 items
- [ ] Add links block to end of About section
- [ ] Update Graduate RA description with Kymera Systems role
- [ ] Post first content piece this week
- [ ] Schedule weekly posting (pick a day)
- [ ] Follow 10-15 XAI/ML researchers
- [ ] Engage on 5 posts daily for algorithm visibility

---

## What's Already Done (Automated)

- [x] GitHub Profile README (`astoreyai/astoreyai`) - pushed
- [x] GitProfile portfolio site (`astoreyai.github.io`) - deployed
- [x] 100DaysML config updated - baseurl, copyright
- [x] All dates updated to Proposal: Jan 2026 / Defense: Nov 2026
- [x] Kymera Systems AI Engineer role added everywhere
